{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35959\n",
      "8246\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# define the model\n",
    "def create_lstm_model(units, vocab_length, embedding_matrix, max_len, dropout):\n",
    "    lstm_model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_length, 200, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "    lstm_model.add(embedding_layer)\n",
    "    lstm_model.add(Dropout(dropout))\n",
    "    lstm_model.add(LSTM(units))\n",
    "    lstm_model.add(Dense(5, activation='softmax'))\n",
    "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "#tf.random.set_seed(7)\n",
    "\n",
    "df = pd.read_csv('../../data/normalized_tweets.csv')\n",
    "df = df[df['cyberbullying_type'] != 'other_cyberbullying']\n",
    "# Reset index after filtering out the class\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#df[\"cyberbullying_type\"].value_counts()\n",
    "\n",
    "### try different length based on tweet lentgh\n",
    "#df['text_len'] = [len(text.split()) for text in df.tweet_text]\n",
    "#max_len = np.max(df['text_len'])\n",
    "max_len = 50\n",
    "\n",
    "X, y = df[\"tweet_text\"], df[\"cyberbullying_type\"]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform label encoder on the target variable\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#Each word in input used as a key, while a unique index is used as the value of the key \n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "X_train = word_tokenizer.texts_to_sequences(x_train)\n",
    "X_test = word_tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "print(vocab_length)\n",
    "\n",
    "####\n",
    "\n",
    "X_train = pad_sequences(X_train, padding = 'pre', maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, padding = 'pre', maxlen = max_len)\n",
    "\n",
    "# Load GloVe word embeddings and create a dictionary that willl contain words as keys, and their corresponging embedding list as values. \n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('../../glove_embeddings/glove.twitter.27B.200d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_length, 200)) ## change if the dimention of embedding changes above\n",
    "i = 0\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "    else:\n",
    "        i = i + 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,  4026, 16244,    56,     7,    14,     5,\n",
       "           1,   304,   914,    14,    71], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.4757 - acc: 0.8361 - val_loss: 0.2715 - val_acc: 0.9062\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 0.2515 - acc: 0.9124 - val_loss: 0.2404 - val_acc: 0.9150\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 0.2101 - acc: 0.9261 - val_loss: 0.2286 - val_acc: 0.9216\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 7s 26ms/step - loss: 0.1845 - acc: 0.9334 - val_loss: 0.2157 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 0.1649 - acc: 0.9401 - val_loss: 0.2184 - val_acc: 0.9228\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 7s 28ms/step - loss: 0.1473 - acc: 0.9459 - val_loss: 0.2171 - val_acc: 0.9253\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.1318 - acc: 0.9528 - val_loss: 0.2206 - val_acc: 0.9238\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 8s 31ms/step - loss: 0.1184 - acc: 0.9574 - val_loss: 0.2186 - val_acc: 0.9263\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.1076 - acc: 0.9616 - val_loss: 0.2342 - val_acc: 0.9260\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 9s 34ms/step - loss: 0.0958 - acc: 0.9653 - val_loss: 0.2214 - val_acc: 0.9292\n",
      "160/160 [==============================] - 2s 12ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 10s 34ms/step - loss: 0.4786 - acc: 0.8314 - val_loss: 0.2790 - val_acc: 0.9001\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 9s 34ms/step - loss: 0.2538 - acc: 0.9093 - val_loss: 0.2383 - val_acc: 0.9177\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 0.2115 - acc: 0.9243 - val_loss: 0.2361 - val_acc: 0.9177\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 0.1873 - acc: 0.9330 - val_loss: 0.2224 - val_acc: 0.9228\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 0.1680 - acc: 0.9394 - val_loss: 0.2310 - val_acc: 0.9209\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 0.1531 - acc: 0.9448 - val_loss: 0.2182 - val_acc: 0.9250\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 9s 35ms/step - loss: 0.1377 - acc: 0.9493 - val_loss: 0.2183 - val_acc: 0.9277\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.1228 - acc: 0.9566 - val_loss: 0.2229 - val_acc: 0.9267\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 12s 46ms/step - loss: 0.1117 - acc: 0.9598 - val_loss: 0.2345 - val_acc: 0.9216\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.1024 - acc: 0.9637 - val_loss: 0.2406 - val_acc: 0.9228\n",
      "160/160 [==============================] - 3s 17ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 14s 49ms/step - loss: 0.4732 - acc: 0.8380 - val_loss: 0.2723 - val_acc: 0.9035\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 13s 49ms/step - loss: 0.2533 - acc: 0.9096 - val_loss: 0.2405 - val_acc: 0.9138\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.2145 - acc: 0.9237 - val_loss: 0.2222 - val_acc: 0.9260\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 13s 49ms/step - loss: 0.1875 - acc: 0.9339 - val_loss: 0.2100 - val_acc: 0.9294\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.1718 - acc: 0.9387 - val_loss: 0.2198 - val_acc: 0.9265\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.1526 - acc: 0.9469 - val_loss: 0.2200 - val_acc: 0.9233\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1400 - acc: 0.9505 - val_loss: 0.2132 - val_acc: 0.9280\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1237 - acc: 0.9551 - val_loss: 0.2091 - val_acc: 0.9302\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 13s 49ms/step - loss: 0.1135 - acc: 0.9587 - val_loss: 0.2070 - val_acc: 0.9326\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.1036 - acc: 0.9629 - val_loss: 0.1994 - val_acc: 0.9341\n",
      "160/160 [==============================] - 3s 16ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 22s 83ms/step - loss: 0.4107 - acc: 0.8549 - val_loss: 0.2689 - val_acc: 0.9038\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 22s 86ms/step - loss: 0.2427 - acc: 0.9146 - val_loss: 0.2390 - val_acc: 0.9184\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 21s 81ms/step - loss: 0.1989 - acc: 0.9281 - val_loss: 0.2217 - val_acc: 0.9223\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 22s 84ms/step - loss: 0.1701 - acc: 0.9384 - val_loss: 0.2062 - val_acc: 0.9280\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 22s 86ms/step - loss: 0.1471 - acc: 0.9470 - val_loss: 0.2161 - val_acc: 0.9265\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.1317 - acc: 0.9532 - val_loss: 0.2173 - val_acc: 0.9292\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 22s 87ms/step - loss: 0.1153 - acc: 0.9593 - val_loss: 0.2240 - val_acc: 0.9284\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 21s 83ms/step - loss: 0.0969 - acc: 0.9646 - val_loss: 0.2292 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 23s 88ms/step - loss: 0.0804 - acc: 0.9722 - val_loss: 0.2492 - val_acc: 0.9263\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 22s 87ms/step - loss: 0.0691 - acc: 0.9768 - val_loss: 0.2526 - val_acc: 0.9226\n",
      "160/160 [==============================] - 5s 28ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 22s 82ms/step - loss: 0.4187 - acc: 0.8514 - val_loss: 0.3031 - val_acc: 0.8962\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 21s 81ms/step - loss: 0.2467 - acc: 0.9114 - val_loss: 0.2343 - val_acc: 0.9184\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 20s 80ms/step - loss: 0.2035 - acc: 0.9283 - val_loss: 0.2246 - val_acc: 0.9221\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 21s 81ms/step - loss: 0.1764 - acc: 0.9367 - val_loss: 0.2150 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.1553 - acc: 0.9437 - val_loss: 0.2204 - val_acc: 0.9243\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 22s 84ms/step - loss: 0.1342 - acc: 0.9513 - val_loss: 0.2257 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 22s 87ms/step - loss: 0.1179 - acc: 0.9562 - val_loss: 0.2361 - val_acc: 0.9201\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 21s 83ms/step - loss: 0.1007 - acc: 0.9640 - val_loss: 0.2302 - val_acc: 0.9253\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.0820 - acc: 0.9708 - val_loss: 0.2475 - val_acc: 0.9250\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.0640 - acc: 0.9774 - val_loss: 0.2618 - val_acc: 0.9204\n",
      "160/160 [==============================] - 4s 21ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 18s 64ms/step - loss: 0.4117 - acc: 0.8537 - val_loss: 0.2838 - val_acc: 0.9035\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.2380 - acc: 0.9152 - val_loss: 0.2217 - val_acc: 0.9179\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 16s 62ms/step - loss: 0.2009 - acc: 0.9286 - val_loss: 0.2122 - val_acc: 0.9297\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.1715 - acc: 0.9393 - val_loss: 0.2109 - val_acc: 0.9265\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.1505 - acc: 0.9455 - val_loss: 0.2013 - val_acc: 0.9289\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 16s 62ms/step - loss: 0.1312 - acc: 0.9518 - val_loss: 0.2121 - val_acc: 0.9314\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.1116 - acc: 0.9592 - val_loss: 0.2071 - val_acc: 0.9321\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.0927 - acc: 0.9649 - val_loss: 0.2261 - val_acc: 0.9284\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 16s 62ms/step - loss: 0.0772 - acc: 0.9728 - val_loss: 0.2365 - val_acc: 0.9284\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.0664 - acc: 0.9777 - val_loss: 0.2355 - val_acc: 0.9326\n",
      "160/160 [==============================] - 3s 20ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 12s 42ms/step - loss: 0.4816 - acc: 0.8356 - val_loss: 0.2770 - val_acc: 0.9055\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 10s 40ms/step - loss: 0.2513 - acc: 0.9132 - val_loss: 0.2446 - val_acc: 0.9140\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 0.2059 - acc: 0.9272 - val_loss: 0.2302 - val_acc: 0.9233\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 0.1838 - acc: 0.9362 - val_loss: 0.2227 - val_acc: 0.9211\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 0.1579 - acc: 0.9464 - val_loss: 0.2153 - val_acc: 0.9275\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 10s 40ms/step - loss: 0.1437 - acc: 0.9493 - val_loss: 0.2113 - val_acc: 0.9277\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 0.1344 - acc: 0.9520 - val_loss: 0.2131 - val_acc: 0.9297\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 0.1131 - acc: 0.9620 - val_loss: 0.2318 - val_acc: 0.9275\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 11s 41ms/step - loss: 0.1052 - acc: 0.9618 - val_loss: 0.2328 - val_acc: 0.9243\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 0.0921 - acc: 0.9669 - val_loss: 0.2329 - val_acc: 0.9228\n",
      "160/160 [==============================] - 3s 17ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 14s 49ms/step - loss: 0.4885 - acc: 0.8289 - val_loss: 0.2803 - val_acc: 0.9021\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.2556 - acc: 0.9098 - val_loss: 0.2379 - val_acc: 0.9175\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.2166 - acc: 0.9228 - val_loss: 0.2369 - val_acc: 0.9187\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1879 - acc: 0.9346 - val_loss: 0.2226 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1681 - acc: 0.9402 - val_loss: 0.2162 - val_acc: 0.9245\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 13s 49ms/step - loss: 0.1553 - acc: 0.9436 - val_loss: 0.2140 - val_acc: 0.9223\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.1413 - acc: 0.9493 - val_loss: 0.2184 - val_acc: 0.9231\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1321 - acc: 0.9522 - val_loss: 0.2215 - val_acc: 0.9258\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1134 - acc: 0.9591 - val_loss: 0.2254 - val_acc: 0.9236\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.1024 - acc: 0.9641 - val_loss: 0.2424 - val_acc: 0.9214\n",
      "160/160 [==============================] - 3s 17ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 14s 49ms/step - loss: 0.4715 - acc: 0.8352 - val_loss: 0.2750 - val_acc: 0.9011\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.2513 - acc: 0.9107 - val_loss: 0.2505 - val_acc: 0.9133\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.2112 - acc: 0.9252 - val_loss: 0.2174 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.1832 - acc: 0.9360 - val_loss: 0.2116 - val_acc: 0.9260\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 13s 50ms/step - loss: 0.1663 - acc: 0.9408 - val_loss: 0.2040 - val_acc: 0.9289\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 13s 49ms/step - loss: 0.1487 - acc: 0.9471 - val_loss: 0.2051 - val_acc: 0.9309\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.1350 - acc: 0.9512 - val_loss: 0.1966 - val_acc: 0.9321\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 12s 47ms/step - loss: 0.1186 - acc: 0.9589 - val_loss: 0.2054 - val_acc: 0.9304\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 13s 52ms/step - loss: 0.1029 - acc: 0.9623 - val_loss: 0.2040 - val_acc: 0.9287\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.0975 - acc: 0.9648 - val_loss: 0.2137 - val_acc: 0.9292\n",
      "160/160 [==============================] - 3s 17ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 21s 78ms/step - loss: 0.4148 - acc: 0.8557 - val_loss: 0.2603 - val_acc: 0.9079\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 20s 78ms/step - loss: 0.2394 - acc: 0.9151 - val_loss: 0.2416 - val_acc: 0.9126\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 21s 83ms/step - loss: 0.1982 - acc: 0.9298 - val_loss: 0.2203 - val_acc: 0.9216\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 21s 82ms/step - loss: 0.1719 - acc: 0.9375 - val_loss: 0.2091 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 20s 80ms/step - loss: 0.1517 - acc: 0.9452 - val_loss: 0.2062 - val_acc: 0.9289\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 19s 76ms/step - loss: 0.1253 - acc: 0.9564 - val_loss: 0.2149 - val_acc: 0.9289\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 20s 80ms/step - loss: 0.1120 - acc: 0.9604 - val_loss: 0.2339 - val_acc: 0.9233\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 21s 82ms/step - loss: 0.0911 - acc: 0.9671 - val_loss: 0.2328 - val_acc: 0.9241\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 21s 82ms/step - loss: 0.0788 - acc: 0.9723 - val_loss: 0.2269 - val_acc: 0.9282\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 20s 79ms/step - loss: 0.0620 - acc: 0.9795 - val_loss: 0.2585 - val_acc: 0.9289\n",
      "160/160 [==============================] - 3s 19ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 17s 64ms/step - loss: 0.4183 - acc: 0.8493 - val_loss: 0.2688 - val_acc: 0.9038\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.2425 - acc: 0.9148 - val_loss: 0.2312 - val_acc: 0.9182\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.2020 - acc: 0.9285 - val_loss: 0.2249 - val_acc: 0.9194\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1730 - acc: 0.9383 - val_loss: 0.2147 - val_acc: 0.9245\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1569 - acc: 0.9442 - val_loss: 0.2185 - val_acc: 0.9272\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1396 - acc: 0.9495 - val_loss: 0.2065 - val_acc: 0.9267\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1161 - acc: 0.9585 - val_loss: 0.2211 - val_acc: 0.9282\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1015 - acc: 0.9638 - val_loss: 0.2223 - val_acc: 0.9245\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.0852 - acc: 0.9687 - val_loss: 0.2325 - val_acc: 0.9299\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.0704 - acc: 0.9755 - val_loss: 0.2519 - val_acc: 0.9258\n",
      "160/160 [==============================] - 3s 20ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 18s 65ms/step - loss: 0.4121 - acc: 0.8575 - val_loss: 0.2559 - val_acc: 0.9133\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.2418 - acc: 0.9142 - val_loss: 0.2352 - val_acc: 0.9209\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.2053 - acc: 0.9266 - val_loss: 0.2080 - val_acc: 0.9306\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1723 - acc: 0.9383 - val_loss: 0.2132 - val_acc: 0.9253\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1551 - acc: 0.9424 - val_loss: 0.2015 - val_acc: 0.9297\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1365 - acc: 0.9514 - val_loss: 0.2014 - val_acc: 0.9314\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1166 - acc: 0.9566 - val_loss: 0.2001 - val_acc: 0.9311\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.0998 - acc: 0.9641 - val_loss: 0.2004 - val_acc: 0.9346\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.0814 - acc: 0.9701 - val_loss: 0.2126 - val_acc: 0.9306\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.0677 - acc: 0.9761 - val_loss: 0.2155 - val_acc: 0.9297\n",
      "160/160 [==============================] - 4s 21ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 11s 40ms/step - loss: 0.4761 - acc: 0.8334 - val_loss: 0.2655 - val_acc: 0.9092\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.2499 - acc: 0.9115 - val_loss: 0.2347 - val_acc: 0.9155\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.2122 - acc: 0.9249 - val_loss: 0.2188 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.1831 - acc: 0.9352 - val_loss: 0.2125 - val_acc: 0.9275\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.1627 - acc: 0.9424 - val_loss: 0.2051 - val_acc: 0.9250\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.1444 - acc: 0.9478 - val_loss: 0.2118 - val_acc: 0.9306\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.1270 - acc: 0.9543 - val_loss: 0.2190 - val_acc: 0.9267\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 0.1156 - acc: 0.9605 - val_loss: 0.2108 - val_acc: 0.9270\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 0.1032 - acc: 0.9637 - val_loss: 0.2118 - val_acc: 0.9304\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 0.0918 - acc: 0.9676 - val_loss: 0.2403 - val_acc: 0.9270\n",
      "160/160 [==============================] - 2s 13ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 11s 38ms/step - loss: 0.4718 - acc: 0.8369 - val_loss: 0.2649 - val_acc: 0.9114\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.2465 - acc: 0.9134 - val_loss: 0.2405 - val_acc: 0.9194\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 10s 37ms/step - loss: 0.2115 - acc: 0.9255 - val_loss: 0.2298 - val_acc: 0.9189\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 10s 37ms/step - loss: 0.1842 - acc: 0.9342 - val_loss: 0.2236 - val_acc: 0.9231\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.1664 - acc: 0.9394 - val_loss: 0.2285 - val_acc: 0.9248\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.1524 - acc: 0.9463 - val_loss: 0.2100 - val_acc: 0.9272\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.1333 - acc: 0.9529 - val_loss: 0.2148 - val_acc: 0.9272\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.1223 - acc: 0.9569 - val_loss: 0.2213 - val_acc: 0.9282\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.1083 - acc: 0.9603 - val_loss: 0.2310 - val_acc: 0.9221\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 0.0926 - acc: 0.9674 - val_loss: 0.2242 - val_acc: 0.9275\n",
      "160/160 [==============================] - 2s 13ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 11s 37ms/step - loss: 0.4759 - acc: 0.8377 - val_loss: 0.2746 - val_acc: 0.9018\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 0.2547 - acc: 0.9106 - val_loss: 0.2278 - val_acc: 0.9241\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 0.2106 - acc: 0.9264 - val_loss: 0.2114 - val_acc: 0.9299\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 0.1880 - acc: 0.9330 - val_loss: 0.2125 - val_acc: 0.9277\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 0.1667 - acc: 0.9398 - val_loss: 0.2005 - val_acc: 0.9321\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 0.1497 - acc: 0.9467 - val_loss: 0.2059 - val_acc: 0.9314\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 0.1349 - acc: 0.9520 - val_loss: 0.2104 - val_acc: 0.9314\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 0.1200 - acc: 0.9579 - val_loss: 0.1983 - val_acc: 0.9304\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 9s 36ms/step - loss: 0.1081 - acc: 0.9614 - val_loss: 0.2007 - val_acc: 0.9292\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 0.0931 - acc: 0.9673 - val_loss: 0.2159 - val_acc: 0.9270\n",
      "160/160 [==============================] - 2s 12ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 17s 63ms/step - loss: 0.4211 - acc: 0.8510 - val_loss: 0.2730 - val_acc: 0.9067\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.2442 - acc: 0.9140 - val_loss: 0.2288 - val_acc: 0.9194\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.1990 - acc: 0.9286 - val_loss: 0.2116 - val_acc: 0.9275\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.1697 - acc: 0.9392 - val_loss: 0.2280 - val_acc: 0.9221\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.1482 - acc: 0.9462 - val_loss: 0.2077 - val_acc: 0.9253\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.1262 - acc: 0.9543 - val_loss: 0.2158 - val_acc: 0.9236\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.1093 - acc: 0.9605 - val_loss: 0.2179 - val_acc: 0.9277\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.0905 - acc: 0.9685 - val_loss: 0.2213 - val_acc: 0.9280\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 19s 75ms/step - loss: 0.0753 - acc: 0.9741 - val_loss: 0.2357 - val_acc: 0.9248\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 20s 80ms/step - loss: 0.0628 - acc: 0.9784 - val_loss: 0.2501 - val_acc: 0.9306\n",
      "160/160 [==============================] - 4s 26ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 22s 83ms/step - loss: 0.4259 - acc: 0.8532 - val_loss: 0.2630 - val_acc: 0.9072\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.2452 - acc: 0.9144 - val_loss: 0.2411 - val_acc: 0.9131\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 21s 83ms/step - loss: 0.2072 - acc: 0.9272 - val_loss: 0.2258 - val_acc: 0.9194\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 16s 63ms/step - loss: 0.1769 - acc: 0.9368 - val_loss: 0.2231 - val_acc: 0.9248\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.1545 - acc: 0.9444 - val_loss: 0.2086 - val_acc: 0.9280\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.1389 - acc: 0.9499 - val_loss: 0.2283 - val_acc: 0.9236\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.1190 - acc: 0.9557 - val_loss: 0.2349 - val_acc: 0.9219\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.0976 - acc: 0.9661 - val_loss: 0.2301 - val_acc: 0.9255\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.0860 - acc: 0.9689 - val_loss: 0.2372 - val_acc: 0.9243\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.0654 - acc: 0.9783 - val_loss: 0.2667 - val_acc: 0.9206\n",
      "160/160 [==============================] - 2s 15ms/step\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 12s 44ms/step - loss: 0.4292 - acc: 0.8528 - val_loss: 0.2741 - val_acc: 0.9065\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 11s 45ms/step - loss: 0.2437 - acc: 0.9137 - val_loss: 0.2278 - val_acc: 0.9245\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 12s 45ms/step - loss: 0.2049 - acc: 0.9269 - val_loss: 0.2229 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 12s 46ms/step - loss: 0.1766 - acc: 0.9388 - val_loss: 0.2038 - val_acc: 0.9321\n",
      "Epoch 5/10\n",
      " 93/256 [=========>....................] - ETA: 6s - loss: 0.1447 - acc: 0.9511"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Define early stopping\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m#early_stopping = EarlyStopping(monitor='val_loss', patience=2)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m# Perform grid search\u001b[39;00m\n\u001b[1;32m     28\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/scikeras/wrappers.py:1491\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     sample_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight\n\u001b[1;32m   1490\u001b[0m     sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, y\u001b[39m=\u001b[39my)\n\u001b[0;32m-> 1491\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, sample_weight\u001b[39m=\u001b[39;49msample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1492\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/scikeras/wrappers.py:760\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    756\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfit__epochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m    757\u001b[0m )\n\u001b[1;32m    758\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 760\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    761\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    762\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    763\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    764\u001b[0m     warm_start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarm_start,\n\u001b[1;32m    765\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    766\u001b[0m )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/scikeras/wrappers.py:928\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_encoder_\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    926\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 928\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_keras_model(\n\u001b[1;32m    929\u001b[0m     X,\n\u001b[1;32m    930\u001b[0m     y,\n\u001b[1;32m    931\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    932\u001b[0m     warm_start\u001b[39m=\u001b[39;49mwarm_start,\n\u001b[1;32m    933\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    934\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    935\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    936\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/scikeras/wrappers.py:524\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m warm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistory_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m initial_epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory_ \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf_env4/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "model = KerasClassifier(model=create_lstm_model, units=128, batch_size=64, dropout=0.2, validation_split=0.2,optimizer__learning_rate=0.1, vocab_length=vocab_length, embedding_matrix=embedding_matrix, max_len=max_len)\n",
    "\n",
    "# Define the grid search parameters\n",
    "#param_grid = {\n",
    "   # 'optimizer__learning_rate': [0.0001, 0.001, 0.1],\n",
    "   # 'dropout': [None, 0.1, 0.2, 0.3, 0.5],\n",
    "   # 'epochs': [5, 10],\n",
    "   # 'units' : [32,64,128,256],\n",
    "   # 'batch_size' : [32, 64, 128,256]\n",
    "#}\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer__learning_rate': [0.001, 0.005, 0.01],\n",
    "    'dropout': [0.1, 0.5],\n",
    "    'epochs': [10],\n",
    "    'units' : [64,128],\n",
    "    'batch_size' : [64]\n",
    "}\n",
    "\n",
    "# Define early stopping\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=0)\n",
    "grid_result = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.929246 using {'batch_size': 64, 'dropout': 0.5, 'epochs': 10, 'optimizer__learning_rate': 0.001, 'units': 128}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "  #  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_model_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Plotting\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mplot(lstm_model_history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(lstm_model_history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel Accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_model_history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.plot(lstm_model_history.history['acc'])\n",
    "plt.plot(lstm_model_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lstm_model_history.history['loss'])\n",
    "plt.plot(lstm_model_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env4)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
