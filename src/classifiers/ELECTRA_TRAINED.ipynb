{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ElectraForSequenceClassification, ElectraTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import import_ipynb\n",
    "from data_preparation import Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Definizione del modello ELECTRA\n",
    "model_name = 'google/electra-base-discriminator'\n",
    "tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
    "num_labels = 5  # Numero di classi\n",
    "model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tweet_BERT(tweet):\n",
    "    tweet = Preprocessing.remove_links_mentions(tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = Preprocessing.remove_hashtag(tweet)\n",
    "    tweet = Preprocessing.remove_special_characters(tweet)\n",
    " \n",
    "    tweet = Preprocessing.remove_spaces(tweet)\n",
    "    tweet = Preprocessing.remove_textual_emojis(tweet)\n",
    "    tweet = Preprocessing.remove_not_ASCII(tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe per il dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, max_length):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.data['tweet_text'] = self.data['tweet_text'].apply(normalize_tweet_BERT)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['tweet_text']\n",
    "        label = self.data.iloc[idx]['cyberbullying_type']\n",
    "        # Mappatura delle etichette alle nuove classi\n",
    "        label_map = {\n",
    "            \"not_cyberbullying\": 0,\n",
    "            \"age\": 1,\n",
    "            \"gender\": 2,\n",
    "            \"ethnicity\": 3,\n",
    "            \"religion\": 4\n",
    "        }\n",
    "        label_id = label_map[label]\n",
    "        encoding = tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label_id, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divido il dataset in training e validation set mantenendo la distribuzione delle classi\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=None)\n",
    "\n",
    "# Creare una colonna per segnare il tipo di dato\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "# Assegna 'train' ai dati di addestramento e 'val' ai dati di validazione nel DataFrame\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "# Conta i valori per ogni combinazione di categoria, etichetta e tipo di dato\n",
    "df.groupby(['cyberbullying_type', 'label', 'data_type']).count()\n",
    "\n",
    "\n",
    "\n",
    "# Caricamento del dataset\n",
    "train_dataset = CustomDataset('../../data/updated_tweets.csv', max_length=64)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di addestramento\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impostazione di parametri per l'addestramento\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio del modello\n",
    "torch.save(model.state_dict(), 'electra_cyberbullying_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
