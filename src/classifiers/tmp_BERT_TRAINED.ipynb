{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6406adc-7273-4fbb-9dae-b6ee9e4fc153",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65c6ac",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c11e6d-ea4b-4f37-bb7d-d9bc77b7a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b6f2f1-3ee0-4e3c-ab04-4ff181694ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/train_tweets_Transformers.csv')\n",
    "eval_df = pd.read_csv('../../data/eval_tweets_Transformers.csv')\n",
    "test_df = pd.read_csv('../../data/test_tweets_Transformers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e0ad8-0e47-4732-9677-ab5317586490",
   "metadata": {},
   "source": [
    "### Labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf879a08-3774-4c1f-8d44-5931d715e9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "possible_labels = train_df.cyberbullying_type.unique()\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_dict = le.fit_transform(possible_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725ddd8-9b25-4b09-808a-6c03872bb315",
   "metadata": {},
   "source": [
    "Sostituiamo nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95cecf9f-88dc-4547-8261-5c42cc9ea66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['label'] = le.fit_transform(train_df['cyberbullying_type'])\n",
    "eval_df['label'] = le.fit_transform(eval_df['cyberbullying_type'])\n",
    "test_df['label'] = le.fit_transform(test_df['cyberbullying_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48697c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not true but when world colored by bigotry/rac...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u bully one white kid in ur school's christian...</td>\n",
       "      <td>age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its not a gay rape joke which i often complain...</td>\n",
       "      <td>gender</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  label\n",
       "0  not true but when world colored by bigotry/rac...          ethnicity      1\n",
       "1  u bully one white kid in ur school's christian...                age      0\n",
       "2  its not a gay rape joke which i often complain...             gender      2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "107f14a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey, do you have a good way to consume multipl...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argg need sleep xx fuckin school today and foc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they fired vic for a jellybean joke while maki...</td>\n",
       "      <td>gender</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  label\n",
       "0  hey, do you have a good way to consume multipl...  not_cyberbullying      3\n",
       "1  argg need sleep xx fuckin school today and foc...  not_cyberbullying      3\n",
       "2  they fired vic for a jellybean joke while maki...             gender      2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed9f4e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2much blacks died for da right 2 vote go vote....</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mitt is gonna win , cant wait to shackle up so...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's nikki's hot pot but she has katie make th...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  label\n",
       "0  2much blacks died for da right 2 vote go vote....          ethnicity      1\n",
       "1  mitt is gonna win , cant wait to shackle up so...          ethnicity      1\n",
       "2  it's nikki's hot pot but she has katie make th...  not_cyberbullying      3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee57b7-80cb-4c05-be58-b3304bbc4a34",
   "metadata": {},
   "source": [
    "### BertTokenizer and Encoding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567992b-b170-4430-80ab-ca93d1d15724",
   "metadata": {},
   "source": [
    "**We have to perform _Tokenization_ --> take raw texts and split into tokens, which are numeric data to represent words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "941c3709-bfb1-4a68-a006-b1bc086f8310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inizializzazione del tokenizer BERT basato su WordPiece, \n",
    "# instanziando una configurazione bert-base (12 layer) e uncased, dato che durante il preprocessing abbiamo eliminato le lettere maiuscole\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb96c97-838f-42e0-abb0-cb7ad6cc49fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f86a94e0-5b3b-4060-887e-c27898f5a1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df.tweet_text.values, \n",
    "        add_special_tokens = True,         # Add [CLS] and [SEP] special tokens\n",
    "        return_attention_mask = True,      # it will return the attention mask according to the specific tokenizer defined by the max_length attribute\n",
    "        max_length = MAX_LEN,\n",
    "        padding = 'max_length', \n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'              # return pytorch, i tensori servono a rappresentare e manipolare dati multidimensionali in modo efficiente\n",
    "    )\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd9de807-1baf-41eb-b334-12eb8c3c773d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Codifica i dati\n",
    "encoded_data_train = encode_data(train_df)\n",
    "encoded_data_val = encode_data(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f35016b-efd3-46ba-a091-98d6036d8314",
   "metadata": {},
   "source": [
    "Split the data into input_ids, attention_masks and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72b7471c-a3c8-47da-817c-6767c5aa7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type == ENCODE_DATA_TYPES[0]].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type == ENCODE_DATA_TYPES[1]].label.values)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aac23c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/HLT/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:267\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'set_format'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_data_train\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/HLT/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:269\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoded_data_train.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318cd30-e42a-4afb-b36a-2e80ef9a34bf",
   "metadata": {},
   "source": [
    "Finally, after we get encoded data set, we can create training data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093d0444-05c0-4770-92f7-bc9f4527fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorDataset consente di creare un dataset basato su tensori, \n",
    "# utile soprattutto quando si lavora con dati che possono essere rappresentati come tensori\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f280a1e2-cae6-496b-8710-08d0e38281c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33303, 5878)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c903d-9163-4e65-a067-584153de1c99",
   "metadata": {},
   "source": [
    "### BERT Pre-trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e135e7-6518-4222-95d0-163d65beb6c8",
   "metadata": {},
   "source": [
    "_bert-base-uncased_ is a smaller pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f894cbe-47a6-4362-8e89-fd250c828f21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "# gli ultimi due non sono necessari + settando a False riduciamo il peso computazionale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d359a25-c177-4251-bf0d-5b9357a02c93",
   "metadata": {},
   "source": [
    "- DataLoader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "- We use RandomSampler for training and SequentialSampler for validation.\n",
    "- Given the limited memory in my environment, I set batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d4d5b3d-cf57-4bbd-912e-80707ea20ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e88f1-474f-499a-a496-bfcd0462e3d7",
   "metadata": {},
   "source": [
    "##### Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8cf845-9cf4-449b-b886-b2de938d789f",
   "metadata": {},
   "source": [
    "- To construct an optimizer, we have to give it an iterable containing the parameters to optimize. Then, we can specify optimizer-specific options such as the learning rate, epsilon, etc\n",
    "- Search for epochs=X which works well for this dataset\n",
    "- Create a schedule with a learning rate that decreases linearly from the initial learning rate set in the optimizer to 0, after a warmup period during which it increases linearly from 0 to the initial learning rate set in the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f07b45b-024a-4d8b-936b-fc39d76edf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g.russo55/HLT/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,   #learning rate\n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 3 # CONTROLLARE VALORE (5)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ea6a7-66ad-4026-ac17-af3410cffcc1",
   "metadata": {},
   "source": [
    "**nota**: epsilon è un piccolo valore aggiunto al denominatore per evitare la divisione per zero o instabilità numerica durante il training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8c5c5-0ad2-445d-bf6a-1814d1784831",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ba33c-0710-42b1-9612-8d62f268614f",
   "metadata": {},
   "source": [
    "We will use f1 score and accuracy per class as performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1aa890-f7b0-47a4-987d-d343c087e5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b12cfe-96bd-4fb1-8d7f-190476b4ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_accuracy(predictions, true_vals):\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "    return accuracy_score(labels_flat, preds_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c56568-7943-4bfa-9c50-42a8ffcee100",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286eebd4-ba66-4453-b034-3d5d5273aa8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0acdaf9-b521-4952-be05-95338365ef99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a73e3f2-bc96-444a-9197-262ab4ff347d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "592fc221-4039-440f-a8bf-8749c8068847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d0494fe-1780-4438-a34b-3cf334fb0c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0baf161094a473eb092e585bdd559f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Average Training loss: 0.32646875974370054\n",
      "Validation loss: 0.1982333490361824\n",
      "F1 Score (Weighted): 0.933089944182388\n",
      "Validation Accuracy: 0.93297039809459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Average Training loss: 0.1465318143839685\n",
      "Validation loss: 0.17283179407873514\n",
      "F1 Score (Weighted): 0.9438388515838645\n",
      "Validation Accuracy: 0.9436883293637292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Average Training loss: 0.10174632099887888\n",
      "Validation loss: 0.18258128317614572\n",
      "F1 Score (Weighted): 0.9426537458830463\n",
      "Validation Accuracy: 0.9424974481116026\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Average Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    val_accuracy = calculate_accuracy(predictions, true_vals)  # Calcolo dell'accuratezza\n",
    "        \n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    tqdm.write(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "torch.save(model.state_dict(), f'../../data/BERT/finetuned_BERT.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83681dec-2aa3-4ed5-b497-4e9e678b694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: not_cyberbullying\n",
      "Accuracy: 1046/1183\n",
      "\n",
      "Class: gender\n",
      "Accuracy: 1043/1160\n",
      "\n",
      "Class: religion\n",
      "Accuracy: 1144/1185\n",
      "\n",
      "Class: age\n",
      "Accuracy: 1175/1199\n",
      "\n",
      "Class: ethnicity\n",
      "Accuracy: 1132/1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('../../data/BERT/finetuned_BERT.model', map_location=device))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7628d1d-13ec-4ff8-89d5-bc0d73f2d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1046   69   45   12   11]\n",
      " [ 110 1043    5    1    1]\n",
      " [  33    4 1144    1    3]\n",
      " [  20    4    0 1175    0]\n",
      " [  10    4    4    1 1132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      1183\n",
      "           1       0.93      0.90      0.91      1160\n",
      "           2       0.95      0.97      0.96      1185\n",
      "           3       0.99      0.98      0.98      1199\n",
      "           4       0.99      0.98      0.99      1151\n",
      "\n",
      "    accuracy                           0.94      5878\n",
      "   macro avg       0.94      0.94      0.94      5878\n",
      "weighted avg       0.94      0.94      0.94      5878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report with checks\n",
    "\n",
    "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "labels_flat = true_vals.flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(labels_flat, preds_flat))\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(labels_flat, preds_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bca08-996b-4367-a422-98a3a79f66e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
