{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6406adc-7273-4fbb-9dae-b6ee9e4fc153",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92bcc2",
   "metadata": {},
   "source": [
    "This notebook demonstrates the process of fine-tuning two BERT models for a sequence classification task\n",
    "\n",
    "#### Steps\n",
    "1. **Configuration and Setup**:\n",
    "    - Define model configurations and hyperparameters.\n",
    "    - Initialize the tokenizer and model configurations.\n",
    "\n",
    "2. **Data Preparation**:\n",
    "    - Load and preprocess the dataset.\n",
    "    - Encode the data using the BERT tokenizer.\n",
    "    - Create DataLoader objects for training, validation, and test sets.\n",
    "\n",
    "3. **Model Training**:\n",
    "    - Define utility functions for training and evaluation.\n",
    "    - Implement early stopping to prevent overfitting.\n",
    "    - Train the model for a specified number of epochs, evaluating on the validation set after each epoch.\n",
    "\n",
    "4. **Evaluation**:\n",
    "    - Evaluate the model on the validation set.\n",
    "    - Calculate and display metrics such as accuracy, confusion matrix, and classification report.\n",
    "    - Save the trained model for future use.\n",
    "\n",
    "#### Key Hyperparameters\n",
    "- **Learning Rate (`LR`)**: Controls the step size during optimization.\n",
    "- **Batch Size (`BATCH_SIZE`)**: Number of samples processed before the model's internal parameters are updated.\n",
    "- **Epochs (`EPOCHS`)**: Number of times the entire dataset is passed through the model.\n",
    "- **Dropout Probabilities (`hidden_dropout_prob` and `attention_probs_dropout_prob`)**: Probabilities of dropping units during training to prevent overfitting.\n",
    "\n",
    "#### Important Notes\n",
    "- **Early Stopping**: Implemented to halt training if the validation loss does not improve for a certain number of epochs.\n",
    "- **Gradient Clipping**: Used to prevent exploding gradients by capping the gradient values during backpropagation.\n",
    "- **Model Saving**: The trained model is saved at the end of the training process for future inference or fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a6b2a0",
   "metadata": {},
   "source": [
    "- bert-base-uncased (model_1)\n",
    "- bert-large-whole-word-masking (model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0925a",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56c11e6d-ea4b-4f37-bb7d-d9bc77b7a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from colorama import Fore, Style\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f74782",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7704334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for bert-base-uncased\n",
    "model_1_info = {\n",
    "    \"NAME\": \"bert-base-uncased\",\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 3,\n",
    "    \"LR\": 1e-5,\n",
    "    \"HID_DP\": 0.5,\n",
    "    \"ATT_DP\": 0.5\n",
    "}\n",
    "\n",
    "# Dictionary for bert-large-whole-word-masking\n",
    "model_2_info = {\n",
    "    \"NAME\": \"bert-large-uncased-whole-word-masking\",\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 4,\n",
    "    \"LR\": 1e-5,\n",
    "    \"HID_DP\": 0.5,\n",
    "    \"ATT_DP\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f447cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 70    # From BERT-like_grids.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5577ecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "529af9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install iProgress\n",
    "#pip install ipywidgets\n",
    "#!pip install ipywidgets --upgrade\n",
    "#!pip install ipywidgets tqdm --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65c6ac",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33b6f2f1-3ee0-4e3c-ab04-4ff181694ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the train, validation and test datasets\n",
    "train_df = pd.read_csv('../../data/New dataset/BERT/train_tweets_Transformers_new.csv')\n",
    "eval_df = pd.read_csv('../../data/New dataset/BERT/eval_tweets_Transformers_new.csv')\n",
    "test_df = pd.read_csv('../../data/New dataset/BERT/test_tweets_Transformers_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e0ad8-0e47-4732-9677-ab5317586490",
   "metadata": {},
   "source": [
    "### Labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf879a08-3774-4c1f-8d44-5931d715e9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ethnicity': 0, 'age': 1, 'gender': 2, 'not_cyberbullying': 3, 'religion': 4} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not true but when world colored by bigotry/rac...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u bully one white kid in ur school's christian...</td>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its not a gay rape joke which i often complain...</td>\n",
       "      <td>gender</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nah dont need explain hope ur well how r u</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hahahaha</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  label\n",
       "0  not true but when world colored by bigotry/rac...          ethnicity      0\n",
       "1  u bully one white kid in ur school's christian...                age      1\n",
       "2  its not a gay rape joke which i often complain...             gender      2\n",
       "3         nah dont need explain hope ur well how r u  not_cyberbullying      3\n",
       "4                                           hahahaha  not_cyberbullying      3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify all unique labels in the training dataset\n",
    "possible_labels = train_df.cyberbullying_type.unique()\n",
    "\n",
    "# Create a dictionary to map each unique label to a numeric index\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "print(label_dict, \"\\n\")\n",
    "\n",
    "# Replace the text labels with numeric labels in the training dataframe\n",
    "# and ensure the column is inferred as the correct data type without copying the data\n",
    "train_df['label'] = train_df.cyberbullying_type.replace(label_dict).infer_objects(copy=False)\n",
    "\n",
    "# Do the same replacement for the validation and test dataframes\n",
    "eval_df['label'] = eval_df.cyberbullying_type.replace(label_dict).infer_objects(copy=False)\n",
    "test_df['label'] = test_df.cyberbullying_type.replace(label_dict).infer_objects(copy=False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725ddd8-9b25-4b09-808a-6c03872bb315",
   "metadata": {},
   "source": [
    "## Define utility functions to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f86a94e0-5b3b-4060-887e-c27898f5a1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the data using the specified tokenizer\n",
    "def encode_data(df, tokenizer):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df.tweet_text.values,               # The tweet texts to be encoded\n",
    "        add_special_tokens = True,          # Add [CLS] and [SEP] special tokens\n",
    "        return_attention_mask = True,       # Return attention masks\n",
    "        max_length = MAX_LEN,\n",
    "        padding = 'max_length',             # Pad to the maximum length\n",
    "        truncation = True,                  # Truncate to the maximum length\n",
    "        return_tensors = 'pt'               # Return PyTorch tensors\n",
    "    )\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e44888af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodes the data and create DataLoader objects for training and validation datasets\n",
    "def get_dataloaders(tokenizer, batch_size):\n",
    "    \n",
    "    # Encode data\n",
    "    encoded_data_train = encode_data(train_df, tokenizer)\n",
    "    encoded_data_val = encode_data(eval_df, tokenizer)\n",
    "    encoded_data_test = encode_data(test_df, tokenizer)\n",
    "\n",
    "    # Extract input_ids_train and attention_masks_train; convert labels into tensors\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(train_df.label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(eval_df.label.values) \n",
    "\n",
    "    input_ids_test = encoded_data_test['input_ids']\n",
    "    attention_masks_test = encoded_data_test['attention_mask']\n",
    "    labels_test = torch.tensor(test_df.label.values)\n",
    "    \n",
    "    # Create datasets based on tensors, combining the input IDs, attention masks, and labels for the training set into a TensorDataset.\n",
    "    # This allows the data to be easily accessed and used by PyTorch's DataLoader.\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "    dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "\n",
    "    # Create DataLoader for the training set with random sampling\n",
    "    dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "    # Create DataLoader for the validation set and test set with sequential sampling\n",
    "    dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "    dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "    return dataloader_train, dataloader_validation, dataloader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632cfbe7",
   "metadata": {},
   "source": [
    "## Define utility functions for compute the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff1aa890-f7b0-47a4-987d-d343c087e5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the accuracy for each class\n",
    "# Parameters\n",
    "# - predictions: predicted values from the model\n",
    "# - labels: true labels from the dataset\n",
    "def accuracy_per_class(predictions, labels):\n",
    "    \n",
    "    # Create an inverse label dictionary to map numeric labels back to their original class names\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Flatten the predictions and labels\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Calculate and print the accuracy for each class\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]    # Predictions for the current class\n",
    "        y_true = labels_flat[labels_flat==label]    # True labels for the current class\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "# Calculate the overall accuracy of the predictions\n",
    "def calculate_accuracy(predictions, true_vals):\n",
    "    # Flatten the predictions and labels\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    # Calculate and return the accuracy score\n",
    "    return accuracy_score(labels_flat, preds_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f0ba2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d0494fe-1780-4438-a34b-3cf334fb0c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Train the model for one epoch.\n",
    "def train_one_epoch(model, history, dataloader_train, optimizer, scheduler):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize progress bar for training\n",
    "    train_progress = tqdm(dataloader_train, desc=\"Training\", leave=False, disable=False)\n",
    "    loss_train_total = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    \n",
    "    for batch in train_progress:\n",
    "\n",
    "        # Zero the gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Move batch to the specified device\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        # Prepare inputs for the model      \n",
    "        inputs = {'input_ids':    batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':         batch[2].long(),\n",
    "                }       \n",
    "\n",
    "        # Forward pass: compute predictions and loss\n",
    "        outputs = model(**inputs) \n",
    "        \n",
    "        # Get the loss from the outputs\n",
    "        loss = outputs[0]   \n",
    "        loss_train_total += loss.item()\n",
    "        \n",
    "        # Backward pass: compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradients to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_progress.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "        # Calculate the number of correct predictions and total samples\n",
    "        _, preds = torch.max(outputs[1], dim=1)\n",
    "        correct_train += torch.sum(preds == inputs['labels'])\n",
    "        total_train += len(inputs['labels'])\n",
    "            \n",
    "    # Calculate the average training loss and accuracy\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    train_acc = correct_train.double() / total_train\n",
    "    tqdm.write(f'Average Training loss: {loss_train_avg}')\n",
    "        \n",
    "    # Append metrics to history\n",
    "    history['train_loss'].append(loss_train_avg)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    return loss_train_avg, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "592fc221-4039-440f-a8bf-8749c8068847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model for one epoch on the validation set\n",
    "def eval_one_epoch(model, history, dataloader_val):\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        # Move batch to the specified device        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        # Prepare inputs for the model        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        # Forward pass: compute predictions and loss without gradient calculation\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU and convert to numpy arrays\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    # Concatenate all predictions and true labels\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    \n",
    "    val_accuracy = calculate_accuracy(predictions, true_vals)\n",
    "\n",
    "    avg_val_loss = loss_val_total/len(dataloader_val) \n",
    "    avg_val_acc = val_accuracy / len(dataloader_val)\n",
    "\n",
    "    tqdm.write(f'Validation loss: {avg_val_loss}')\n",
    "    tqdm.write(f'Validation Accuracy: {val_accuracy}')\n",
    "    \n",
    "    # Append metrics to history\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['val_acc'].append(val_accuracy)\n",
    "    \n",
    "    return avg_val_acc, avg_val_loss, predictions, true_vals, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fdd01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    \"\"\"\n",
    "    Implements early stopping to terminate training when the validation loss stops improving.\n",
    "    \n",
    "    Parameters:\n",
    "    - min_delta: minimum change in the monitored metric to qualify as an improvement\n",
    "    - patience: number of epochs to wait for an improvement before stopping.\n",
    "    - percentage: whether to interpret min_delta as a percentage or an absolute number.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_delta=0, patience=1, percentage=True):\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None            # Best metric observed so far\n",
    "        self.num_bad_epochs = 0     # Counter for epochs with no improvement\n",
    "        self.is_better = None       # Function to determine if the current metric is better than the best observed\n",
    "        self._init_is_better(min_delta, percentage)     # Initialize the comparison function\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics     # Initialize the best metric with the first value\n",
    "            return False            # Continue training\n",
    "\n",
    "        if not isinstance(metrics, torch.Tensor):\n",
    "            metrics = torch.tensor(metrics)\n",
    "            \n",
    "        if torch.isnan(metrics):\n",
    "            print(\"Error: TORCH IS NAN\")\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            # If an improvement is registered, reset the counter and update the best metric\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            # If no improvement, increase the counter\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            # Stop training if the number of bad epochs exceeds patience\n",
    "            print(Fore.BLUE + Style.BRIGHT + 'terminating because of early stopping!'+ Style.RESET_ALL)\n",
    "            return True\n",
    "            \n",
    "        return False    # Continue training\n",
    "\n",
    "    def _init_is_better(self, min_delta, percentage):\n",
    "        if not percentage:\n",
    "            # Use absolute change for comparison\n",
    "            self.is_better = lambda a, best: a < best - min_delta\n",
    "        else:\n",
    "            # Use percentage change for comparison\n",
    "            self.is_better = lambda a, best: a < best - (best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d9bca08-996b-4367-a422-98a3a79f66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(model_info):\n",
    "\n",
    "    \"\"\"\n",
    "    Execute the training and evaluation process for a BERT model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_info: a dictionary containing model configuration such as NAME, BATCH_SIZE, EPOCHS, LR, ...\n",
    "    \n",
    "    Returns:\n",
    "    - model: the trained BERT model\n",
    "    - tokenizer: the tokenizer used for encoding the data\n",
    "    - history: a dictionary containing the training and validation loss and accuracy history\n",
    "    - dataloader_test: DataLoader for the test data\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize history dictionary\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    # Extract model configuration from the dictionary\n",
    "    name = model_info[\"NAME\"]\n",
    "    batch_size = model_info[\"BATCH_SIZE\"]\n",
    "    epochs = model_info[\"EPOCHS\"]\n",
    "    lr = model_info[\"LR\"]\n",
    "    hid_dp = model_info[\"HID_DP\"]\n",
    "    att_dp = model_info[\"ATT_DP\"]\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(name, do_lower_case=True)\n",
    "\n",
    "    # Get DataLoader objects for training, validation and test sets\n",
    "    dataloader_train, dataloader_validation, dataloader_test = get_dataloaders(tokenizer, batch_size)\n",
    "\n",
    "    # Initialize the BERT configuration\n",
    "    config = BertConfig.from_pretrained(name, \n",
    "                                    hidden_dropout_prob=hid_dp,\n",
    "                                    attention_probs_dropout_prob=att_dp,\n",
    "                                    num_labels=len(label_dict),\n",
    "                                    output_attentions=False,\n",
    "                                    output_hidden_states=False)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(name, config=config)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr) \n",
    "                  \n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n",
    "    \n",
    "    # Move the model to the specified device\n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"\\n*** Start TRAINING ***\")\n",
    "    \n",
    "    early_stopping = EarlyStopping(min_delta=5, patience=2)   \n",
    "    train_loss, validation_loss, validation_acc = [], [], []\n",
    "    total_acc_score = 0\n",
    "\n",
    "    for i in range(0, epochs):\n",
    "        print(Fore.GREEN + Style.BRIGHT + f\"Epoch {i+1}\" +Style.RESET_ALL)\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        avg_train_loss_one_epoch, history = train_one_epoch(model, history, dataloader_train, optimizer, scheduler)\n",
    "        train_loss.append(avg_train_loss_one_epoch)\n",
    "\n",
    "        # Validate the model\n",
    "        epoch_acc_score, avg_val_loss_one_epoch, predictions, true_vals, history = eval_one_epoch(model, history, dataloader_validation)\n",
    "        validation_loss.append(avg_val_loss_one_epoch)\n",
    "        validation_acc.append(epoch_acc_score)\n",
    "        \n",
    "        total_acc_score += epoch_acc_score\n",
    "\n",
    "        # Check for early stopping\n",
    "        if early_stopping.step(avg_val_loss_one_epoch):\n",
    "            print(\"We are at epoch:\", i+1)\n",
    "            break\n",
    "    \n",
    "    \n",
    "    print(\"\\n*** END ***\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_name = model.config.name_or_path\n",
    "    torch.save(model.state_dict(), f'../../data/Transformers/finetuned_{model_name}.model')\n",
    "    print(\"\\tModel saved successfully!\")\n",
    "\n",
    "    # Calculate accuracy per class\n",
    "    accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "    # Flatten predictions and labels for confusion matrix and classification report\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    # Print confusion Matrix\n",
    "    print(confusion_matrix(labels_flat, preds_flat))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Print classification Report\n",
    "    print(classification_report(labels_flat, preds_flat, target_names=possible_labels))\n",
    "\n",
    "    return model, tokenizer, history, dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "852a83fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Avvio TRAINING ***\n",
      "\u001b[32m\u001b[1mEpoch 1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c97ba5b23784d37a261f8f3e9f25c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_1, tokenizer_1, history_1, dataloader_test_1 \u001b[38;5;241m=\u001b[39m execute(model_1_info)\n",
      "Cell \u001b[1;32mIn[56], line 66\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(model_info)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(Fore\u001b[38;5;241m.\u001b[39mGREEN \u001b[38;5;241m+\u001b[39m Style\u001b[38;5;241m.\u001b[39mBRIGHT \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39mStyle\u001b[38;5;241m.\u001b[39mRESET_ALL)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Train the model for one epoch\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m avg_train_loss_one_epoch, history \u001b[38;5;241m=\u001b[39m train_one_epoch(model, history, dataloader_train, optimizer, scheduler)\n\u001b[0;32m     67\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(avg_train_loss_one_epoch)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Validate the model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[53], line 27\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, history, dataloader_train, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     21\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:    batch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m:         batch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mlong(),\n\u001b[0;32m     24\u001b[0m         }       \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass: compute predictions and loss\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs) \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the loss from the outputs\u001b[39;00m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]   \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1539\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1539\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   1540\u001b[0m     input_ids,\n\u001b[0;32m   1541\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1542\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1543\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1544\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1545\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1546\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1547\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1548\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1549\u001b[0m )\n\u001b[0;32m   1551\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1553\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    979\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    981\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    982\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    983\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    987\u001b[0m )\n\u001b[1;32m--> 988\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    989\u001b[0m     embedding_output,\n\u001b[0;32m    990\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m    991\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    992\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    993\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m    994\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    995\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    996\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    997\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    998\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    999\u001b[0m )\n\u001b[0;32m   1000\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    572\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    573\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         output_attentions,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    583\u001b[0m         hidden_states,\n\u001b[0;32m    584\u001b[0m         attention_mask,\n\u001b[0;32m    585\u001b[0m         layer_head_mask,\n\u001b[0;32m    586\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    587\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    588\u001b[0m         past_key_value,\n\u001b[0;32m    589\u001b[0m         output_attentions,\n\u001b[0;32m    590\u001b[0m     )\n\u001b[0;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    511\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    512\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 514\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    517\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:526\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 526\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m    527\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alessia\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 426\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    427\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_1, tokenizer_1, history_1, dataloader_test_1 = execute(model_1_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plots(history):\n",
    "    def convert_to_numpy(val):\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            return val.cpu()\n",
    "        return val\n",
    "\n",
    "    # Extract and convert the values\n",
    "    train_loss = [convert_to_numpy(t) for t in history['train_loss']]\n",
    "    val_loss = [convert_to_numpy(t) for t in history['val_loss']]\n",
    "    train_acc = [convert_to_numpy(t) for t in history['train_acc']]\n",
    "    val_acc = [convert_to_numpy(t) for t in history['val_acc']]\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438c6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plots(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07897c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Avvio TRAINING ***\n",
      "\u001b[32m\u001b[1mEpoch 1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd009ffc24f4809825333f656ddb0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_2, tokenizer_2, history_2, dataloader_test_2 = execute(model_2_info)\n",
    "show_plots(history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aeda6e",
   "metadata": {},
   "source": [
    "## Evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader_test):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        input_ids, attention_masks, labels = batch\n",
    "        \n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, token_type_ids=None, \n",
    "                        attention_mask=attention_masks)\n",
    "     \n",
    "        logits = outputs.logits\n",
    "\n",
    "        logits = torch.argmax(logits, dim=1).flatten().cpu().numpy()\n",
    "        label_ids = labels.cpu().numpy()\n",
    " \n",
    "        predictions.extend(logits)\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    print(\"\\t***************\\t\")\n",
    "    # Print confusion Matrix\n",
    "    print(confusion_matrix(true_labels, predictions))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Print classification Report\n",
    "    print(classification_report(true_labels, predictions, target_names=possible_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad681989-ad4f-45f1-8cb0-9b6664640eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.930309881633196\n",
      "Precision: 0.9294219882783665\n",
      "Recall: 0.930309881633196\n",
      "------------\n",
      "[[1454    5   13   22    8]\n",
      " [   4 1537   10   17    0]\n",
      " [   8    8 1342  132    7]\n",
      " [  21   53  102 1084   78]\n",
      " [   5    2    4   25 1578]]\n",
      "\n",
      "\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        ethnicity       0.97      0.97      0.97      1502\n",
      "              age       0.96      0.98      0.97      1568\n",
      "           gender       0.91      0.90      0.90      1497\n",
      "not_cyberbullying       0.85      0.81      0.83      1338\n",
      "         religion       0.94      0.98      0.96      1614\n",
      "\n",
      "         accuracy                           0.93      7519\n",
      "        macro avg       0.93      0.93      0.93      7519\n",
      "     weighted avg       0.93      0.93      0.93      7519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_1, dataloader_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94053833-4297-417e-b1a8-97e7585a9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model_2, dataloader_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc8d8a",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8fff2-6a44-4923-a39a-34453ee17c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device=device):\n",
    "    model.eval()\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    prediction_type = next((chiave for chiave, valore in label_dict.items() \n",
    "                           if valore == prediction), None)\n",
    "    return prediction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_category(sentence):\n",
    "    predicted_category = predict(sentence, model_1, tokenizer_1)\n",
    "    print(f\"Text: {sentence} \\nPredicted Cyberbullying Category: \", end=\"\")\n",
    "    print(Fore.BLUE + Style.BRIGHT + f\"{predicted_category}\"+ Style.RESET_ALL)\n",
    "    print(\"----------------\")\n",
    "    return\n",
    "    \n",
    "print_category(\"Example of a new tweet that could be cyberbullying.\")\n",
    "print_category(\"fuck you black\")\n",
    "print_category(\"i will rape you\")\n",
    "print_category(\"muslim idiot\")\n",
    "print_category(\"hello how are you\")\n",
    "print_category(\"Can anyone else said to this nigger that the dress is blue?\")\n",
    "print_category(\"I'm really happy for your birthday\")\n",
    "print_category(\"In my opinion Allah is not a real god\")\n",
    "print_category(\"I fucking hate Allah\")\n",
    "print_category(\"I appreciate Allah\")\n",
    "print_category(\"Men are better than women\")\n",
    "print_category(\"Bro, you are a Nigga!!!\")\n",
    "print_category(\"You are a shit!!!\")\n",
    "print_category(\"dickhead!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
