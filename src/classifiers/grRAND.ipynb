{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values greater than or equal to 35: 100\n",
      "31487\n",
      "8034\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.stats import uniform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, LSTM, Dense, Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Define early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "# define the model\n",
    "def create_lstm_model(units, vocab_length, embedding_matrix, max_len, dropout):\n",
    "    lstm_model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_length, 200, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
    "    lstm_model.add(embedding_layer)\n",
    "    lstm_model.add(Dropout(dropout))\n",
    "    lstm_model.add(LSTM(units,kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal'))\n",
    "    lstm_model.add(Dense(5, activation='softmax', kernel_initializer='ones'))\n",
    "    lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "#tf.random.set_seed(7)\n",
    "\n",
    "df = pd.read_csv('../../data/normalized_tweets.csv')\n",
    "df = df[df['cyberbullying_type'] != 'other_cyberbullying']\n",
    "# Reset index after filtering out the class\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#df[\"cyberbullying_type\"].value_counts()\n",
    "\n",
    "### try different length based on tweet lentgh\n",
    "df['text_len'] = [len(text.split()) for text in df.tweet_text]\n",
    "#max_len = np.max(df['text_len'])\n",
    "#avg_len = np.mean(df['text_len'])\n",
    "#avg_len = int(avg_len)\n",
    "#print(avg_len)\n",
    "avg_len = 35\n",
    "# checks on tweets length\n",
    "count = (df['text_len'] >= 35).sum()\n",
    "print(\"Number of values greater than or equal to 35:\", count)\n",
    "\n",
    "\n",
    "X, y = df[\"tweet_text\"], df[\"cyberbullying_type\"]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform label encoder on the target variable\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#Each word in input used as a key, while a unique index is used as the value of the key \n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "X_train = word_tokenizer.texts_to_sequences(x_train)\n",
    "X_test = word_tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "print(vocab_length)\n",
    "\n",
    "####\n",
    "\n",
    "X_train = pad_sequences(X_train, padding = 'pre', maxlen = avg_len)\n",
    "X_test = pad_sequences(X_test, padding = 'pre', maxlen = avg_len)\n",
    "\n",
    "# Load GloVe word embeddings and create a dictionary that willl contain words as keys, and their corresponging embedding list as values. \n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('../../glove_embeddings/glove.twitter.27B.200d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_length, 200)) ## change if the dimention of embedding changes above\n",
    "i = 0\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "    else:\n",
    "        i = i + 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,   477,   235,    11,   811,   984,    47,\n",
       "         130,     6,     1, 13475,     9,    92,     2,  2483,   382,\n",
       "         264,  1578,     2,   721,   149,    77,   318,   656],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5770 - acc: 0.8110 - val_loss: 0.3165 - val_acc: 0.8886\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.3000 - acc: 0.8967 - val_loss: 0.2601 - val_acc: 0.9088\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2581 - acc: 0.9098 - val_loss: 0.2324 - val_acc: 0.9170\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2327 - acc: 0.9176 - val_loss: 0.2282 - val_acc: 0.9178\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2165 - acc: 0.9239 - val_loss: 0.2288 - val_acc: 0.9203\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2009 - acc: 0.9281 - val_loss: 0.2154 - val_acc: 0.9265\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5828 - acc: 0.8126 - val_loss: 0.3018 - val_acc: 0.8971\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2997 - acc: 0.8964 - val_loss: 0.2551 - val_acc: 0.9116\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2615 - acc: 0.9085 - val_loss: 0.2422 - val_acc: 0.9150\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2345 - acc: 0.9172 - val_loss: 0.2192 - val_acc: 0.9213\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2197 - acc: 0.9218 - val_loss: 0.2277 - val_acc: 0.9205\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2041 - acc: 0.9280 - val_loss: 0.2095 - val_acc: 0.9287\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5734 - acc: 0.8127 - val_loss: 0.3028 - val_acc: 0.9013\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.3060 - acc: 0.8936 - val_loss: 0.2600 - val_acc: 0.9118\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2631 - acc: 0.9096 - val_loss: 0.2417 - val_acc: 0.9141\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2352 - acc: 0.9183 - val_loss: 0.2255 - val_acc: 0.9208\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2138 - acc: 0.9234 - val_loss: 0.2210 - val_acc: 0.9235\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.1986 - acc: 0.9310 - val_loss: 0.2319 - val_acc: 0.9210\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 6s 20ms/step - loss: 0.7264 - acc: 0.7494 - val_loss: 0.3618 - val_acc: 0.8742\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.3332 - acc: 0.8881 - val_loss: 0.2878 - val_acc: 0.8996\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2787 - acc: 0.9030 - val_loss: 0.2599 - val_acc: 0.9088\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2557 - acc: 0.9098 - val_loss: 0.2358 - val_acc: 0.9150\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2346 - acc: 0.9159 - val_loss: 0.2307 - val_acc: 0.9210\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2179 - acc: 0.9233 - val_loss: 0.2169 - val_acc: 0.9258\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 6s 20ms/step - loss: 0.6935 - acc: 0.7777 - val_loss: 0.3515 - val_acc: 0.8809\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.3292 - acc: 0.8883 - val_loss: 0.2799 - val_acc: 0.8971\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2810 - acc: 0.9023 - val_loss: 0.2636 - val_acc: 0.9063\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2560 - acc: 0.9112 - val_loss: 0.2339 - val_acc: 0.9168\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2411 - acc: 0.9144 - val_loss: 0.2300 - val_acc: 0.9178\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2232 - acc: 0.9197 - val_loss: 0.2219 - val_acc: 0.9203\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 6s 20ms/step - loss: 0.7194 - acc: 0.7494 - val_loss: 0.3294 - val_acc: 0.8974\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 5s 21ms/step - loss: 0.3226 - acc: 0.8923 - val_loss: 0.3021 - val_acc: 0.8989\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2769 - acc: 0.9035 - val_loss: 0.2554 - val_acc: 0.9113\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2516 - acc: 0.9122 - val_loss: 0.2410 - val_acc: 0.9168\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2308 - acc: 0.9188 - val_loss: 0.2298 - val_acc: 0.9218\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2153 - acc: 0.9247 - val_loss: 0.2318 - val_acc: 0.9173\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.6967 - acc: 0.7704 - val_loss: 0.3442 - val_acc: 0.8857\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 4s 9ms/step - loss: 0.3306 - acc: 0.8892 - val_loss: 0.2719 - val_acc: 0.9031\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 4s 9ms/step - loss: 0.2809 - acc: 0.9030 - val_loss: 0.2427 - val_acc: 0.9185\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 4s 9ms/step - loss: 0.2563 - acc: 0.9111 - val_loss: 0.2358 - val_acc: 0.9200\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 4s 9ms/step - loss: 0.2402 - acc: 0.9150 - val_loss: 0.2280 - val_acc: 0.9200\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2270 - acc: 0.9221 - val_loss: 0.2210 - val_acc: 0.9248\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.7023 - acc: 0.7565 - val_loss: 0.3547 - val_acc: 0.8792\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.3249 - acc: 0.8902 - val_loss: 0.2752 - val_acc: 0.9031\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2770 - acc: 0.9060 - val_loss: 0.2487 - val_acc: 0.9133\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2513 - acc: 0.9112 - val_loss: 0.2376 - val_acc: 0.9198\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2340 - acc: 0.9188 - val_loss: 0.2223 - val_acc: 0.9225\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2185 - acc: 0.9241 - val_loss: 0.2158 - val_acc: 0.9243\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.6673 - acc: 0.7867 - val_loss: 0.3290 - val_acc: 0.8969\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.3288 - acc: 0.8903 - val_loss: 0.2732 - val_acc: 0.9086\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2828 - acc: 0.9020 - val_loss: 0.2580 - val_acc: 0.9108\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2536 - acc: 0.9127 - val_loss: 0.2506 - val_acc: 0.9155\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2389 - acc: 0.9179 - val_loss: 0.2396 - val_acc: 0.9173\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2197 - acc: 0.9225 - val_loss: 0.2262 - val_acc: 0.9220\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.7055 - acc: 0.7715 - val_loss: 0.3552 - val_acc: 0.8844\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.3302 - acc: 0.8894 - val_loss: 0.2845 - val_acc: 0.9036\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2807 - acc: 0.9031 - val_loss: 0.2411 - val_acc: 0.9165\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2538 - acc: 0.9107 - val_loss: 0.2314 - val_acc: 0.9218\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2366 - acc: 0.9163 - val_loss: 0.2240 - val_acc: 0.9213\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2233 - acc: 0.9191 - val_loss: 0.2244 - val_acc: 0.9238\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.6856 - acc: 0.7918 - val_loss: 0.3512 - val_acc: 0.8854\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.3338 - acc: 0.8914 - val_loss: 0.2818 - val_acc: 0.9031\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2832 - acc: 0.9046 - val_loss: 0.2513 - val_acc: 0.9141\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2560 - acc: 0.9124 - val_loss: 0.2388 - val_acc: 0.9198\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2425 - acc: 0.9153 - val_loss: 0.2236 - val_acc: 0.9193\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2259 - acc: 0.9210 - val_loss: 0.2270 - val_acc: 0.9215\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.7079 - acc: 0.7799 - val_loss: 0.3546 - val_acc: 0.8894\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.3301 - acc: 0.8899 - val_loss: 0.2731 - val_acc: 0.9081\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2794 - acc: 0.9048 - val_loss: 0.2563 - val_acc: 0.9106\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2514 - acc: 0.9135 - val_loss: 0.2490 - val_acc: 0.9165\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2387 - acc: 0.9175 - val_loss: 0.2342 - val_acc: 0.9213\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2202 - acc: 0.9231 - val_loss: 0.2279 - val_acc: 0.9225\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5612 - acc: 0.8200 - val_loss: 0.2918 - val_acc: 0.8966\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2933 - acc: 0.8988 - val_loss: 0.2506 - val_acc: 0.9086\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2549 - acc: 0.9109 - val_loss: 0.2440 - val_acc: 0.9158\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2288 - acc: 0.9189 - val_loss: 0.2170 - val_acc: 0.9228\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2100 - acc: 0.9256 - val_loss: 0.2074 - val_acc: 0.9278\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2002 - acc: 0.9293 - val_loss: 0.2040 - val_acc: 0.9292\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5826 - acc: 0.8116 - val_loss: 0.3142 - val_acc: 0.8854\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2946 - acc: 0.8970 - val_loss: 0.2562 - val_acc: 0.9071\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2542 - acc: 0.9114 - val_loss: 0.2356 - val_acc: 0.9195\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2343 - acc: 0.9165 - val_loss: 0.2235 - val_acc: 0.9223\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2106 - acc: 0.9253 - val_loss: 0.2193 - val_acc: 0.9220\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.1988 - acc: 0.9282 - val_loss: 0.2200 - val_acc: 0.9258\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5866 - acc: 0.8039 - val_loss: 0.3227 - val_acc: 0.8974\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.3103 - acc: 0.8947 - val_loss: 0.2657 - val_acc: 0.9098\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2591 - acc: 0.9092 - val_loss: 0.2391 - val_acc: 0.9158\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2308 - acc: 0.9193 - val_loss: 0.2288 - val_acc: 0.9198\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2140 - acc: 0.9243 - val_loss: 0.2276 - val_acc: 0.9200\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2042 - acc: 0.9259 - val_loss: 0.2196 - val_acc: 0.9253\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5860 - acc: 0.8070 - val_loss: 0.3044 - val_acc: 0.8959\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.3052 - acc: 0.8947 - val_loss: 0.2630 - val_acc: 0.9086\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2620 - acc: 0.9079 - val_loss: 0.2316 - val_acc: 0.9233\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2351 - acc: 0.9163 - val_loss: 0.2257 - val_acc: 0.9223\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2219 - acc: 0.9218 - val_loss: 0.2117 - val_acc: 0.9243\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2016 - acc: 0.9286 - val_loss: 0.2138 - val_acc: 0.9250\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5826 - acc: 0.8085 - val_loss: 0.3266 - val_acc: 0.8842\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2952 - acc: 0.8987 - val_loss: 0.2702 - val_acc: 0.9071\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2564 - acc: 0.9099 - val_loss: 0.2437 - val_acc: 0.9178\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2312 - acc: 0.9173 - val_loss: 0.2289 - val_acc: 0.9233\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2201 - acc: 0.9219 - val_loss: 0.2175 - val_acc: 0.9253\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2023 - acc: 0.9277 - val_loss: 0.2217 - val_acc: 0.9235\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5931 - acc: 0.7984 - val_loss: 0.3069 - val_acc: 0.9013\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.3011 - acc: 0.8959 - val_loss: 0.2698 - val_acc: 0.9058\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2548 - acc: 0.9094 - val_loss: 0.2372 - val_acc: 0.9163\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2293 - acc: 0.9188 - val_loss: 0.2330 - val_acc: 0.9170\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2120 - acc: 0.9242 - val_loss: 0.2161 - val_acc: 0.9218\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.1988 - acc: 0.9289 - val_loss: 0.2108 - val_acc: 0.9260\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 6s 21ms/step - loss: 0.6954 - acc: 0.7839 - val_loss: 0.3734 - val_acc: 0.8667\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.3305 - acc: 0.8874 - val_loss: 0.2865 - val_acc: 0.8971\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2833 - acc: 0.9026 - val_loss: 0.2549 - val_acc: 0.9106\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2575 - acc: 0.9101 - val_loss: 0.2424 - val_acc: 0.9128\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2388 - acc: 0.9150 - val_loss: 0.2207 - val_acc: 0.9218\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2251 - acc: 0.9188 - val_loss: 0.2188 - val_acc: 0.9255\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 6s 21ms/step - loss: 0.7259 - acc: 0.7563 - val_loss: 0.3482 - val_acc: 0.8814\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.3320 - acc: 0.8896 - val_loss: 0.2987 - val_acc: 0.8999\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2826 - acc: 0.9018 - val_loss: 0.2468 - val_acc: 0.9088\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2557 - acc: 0.9108 - val_loss: 0.2291 - val_acc: 0.9183\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2391 - acc: 0.9154 - val_loss: 0.2376 - val_acc: 0.9143\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2227 - acc: 0.9211 - val_loss: 0.2196 - val_acc: 0.9200\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 6s 20ms/step - loss: 0.6965 - acc: 0.7679 - val_loss: 0.3244 - val_acc: 0.8941\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 0.3236 - acc: 0.8938 - val_loss: 0.2732 - val_acc: 0.9108\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 0.2761 - acc: 0.9059 - val_loss: 0.2634 - val_acc: 0.9086\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 0.2489 - acc: 0.9149 - val_loss: 0.2386 - val_acc: 0.9153\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 0.2353 - acc: 0.9171 - val_loss: 0.2430 - val_acc: 0.9170\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 0.2197 - acc: 0.9215 - val_loss: 0.2349 - val_acc: 0.9183\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 4s 13ms/step - loss: 0.8522 - acc: 0.7309 - val_loss: 0.4105 - val_acc: 0.8714\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.3747 - acc: 0.8787 - val_loss: 0.3087 - val_acc: 0.8926\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.3093 - acc: 0.8953 - val_loss: 0.2818 - val_acc: 0.8996\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2828 - acc: 0.9036 - val_loss: 0.2553 - val_acc: 0.9106\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2615 - acc: 0.9102 - val_loss: 0.2414 - val_acc: 0.9183\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2480 - acc: 0.9132 - val_loss: 0.2319 - val_acc: 0.9173\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 4s 12ms/step - loss: 0.8532 - acc: 0.7281 - val_loss: 0.4132 - val_acc: 0.8667\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.3711 - acc: 0.8827 - val_loss: 0.3184 - val_acc: 0.8896\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.3079 - acc: 0.8988 - val_loss: 0.2758 - val_acc: 0.9043\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2813 - acc: 0.9045 - val_loss: 0.2500 - val_acc: 0.9078\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2608 - acc: 0.9111 - val_loss: 0.2442 - val_acc: 0.9131\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2446 - acc: 0.9154 - val_loss: 0.2341 - val_acc: 0.9165\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "251/251 [==============================] - 4s 13ms/step - loss: 0.8405 - acc: 0.7395 - val_loss: 0.3868 - val_acc: 0.8857\n",
      "Epoch 2/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.3625 - acc: 0.8843 - val_loss: 0.2987 - val_acc: 0.9001\n",
      "Epoch 3/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2994 - acc: 0.8988 - val_loss: 0.2738 - val_acc: 0.9096\n",
      "Epoch 4/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2740 - acc: 0.9071 - val_loss: 0.2534 - val_acc: 0.9136\n",
      "Epoch 5/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2564 - acc: 0.9132 - val_loss: 0.2518 - val_acc: 0.9118\n",
      "Epoch 6/6\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.2422 - acc: 0.9159 - val_loss: 0.2344 - val_acc: 0.9195\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5169 - acc: 0.8311 - val_loss: 0.2804 - val_acc: 0.9053\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.2594 - acc: 0.9111 - val_loss: 0.2725 - val_acc: 0.9011\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2166 - acc: 0.9253 - val_loss: 0.2254 - val_acc: 0.9213\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 8s 15ms/step - loss: 0.1922 - acc: 0.9337 - val_loss: 0.2152 - val_acc: 0.9265\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.1738 - acc: 0.9382 - val_loss: 0.2240 - val_acc: 0.9230\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.1578 - acc: 0.9431 - val_loss: 0.2153 - val_acc: 0.9263\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5301 - acc: 0.8241 - val_loss: 0.2892 - val_acc: 0.8981\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.2605 - acc: 0.9109 - val_loss: 0.2469 - val_acc: 0.9138\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.2162 - acc: 0.9244 - val_loss: 0.2308 - val_acc: 0.9158\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.1935 - acc: 0.9329 - val_loss: 0.2284 - val_acc: 0.9188\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.1750 - acc: 0.9396 - val_loss: 0.2191 - val_acc: 0.9223\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.1579 - acc: 0.9435 - val_loss: 0.2111 - val_acc: 0.9250\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.5237 - acc: 0.8235 - val_loss: 0.2864 - val_acc: 0.9063\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2533 - acc: 0.9137 - val_loss: 0.2509 - val_acc: 0.9145\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 6s 13ms/step - loss: 0.2106 - acc: 0.9286 - val_loss: 0.2575 - val_acc: 0.9141\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 7s 14ms/step - loss: 0.1931 - acc: 0.9335 - val_loss: 0.2388 - val_acc: 0.9218\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.1709 - acc: 0.9406 - val_loss: 0.2195 - val_acc: 0.9240\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 7s 13ms/step - loss: 0.1542 - acc: 0.9454 - val_loss: 0.2171 - val_acc: 0.9245\n",
      "314/314 [==============================] - 1s 4ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 6s 10ms/step - loss: 0.6566 - acc: 0.7963 - val_loss: 0.3500 - val_acc: 0.8769\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3230 - acc: 0.8913 - val_loss: 0.2705 - val_acc: 0.9053\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.2788 - acc: 0.9028 - val_loss: 0.2415 - val_acc: 0.9155\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.2518 - acc: 0.9130 - val_loss: 0.2412 - val_acc: 0.9160\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.2400 - acc: 0.9156 - val_loss: 0.2224 - val_acc: 0.9263\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2234 - acc: 0.9214 - val_loss: 0.2201 - val_acc: 0.9255\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.6884 - acc: 0.7781 - val_loss: 0.3311 - val_acc: 0.8921\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.3221 - acc: 0.8937 - val_loss: 0.2784 - val_acc: 0.9053\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2827 - acc: 0.9048 - val_loss: 0.2479 - val_acc: 0.9143\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2560 - acc: 0.9104 - val_loss: 0.2306 - val_acc: 0.9200\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2364 - acc: 0.9190 - val_loss: 0.2199 - val_acc: 0.9243\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2262 - acc: 0.9205 - val_loss: 0.2192 - val_acc: 0.9248\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "502/502 [==============================] - 6s 11ms/step - loss: 0.6962 - acc: 0.7731 - val_loss: 0.3308 - val_acc: 0.8991\n",
      "Epoch 2/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3253 - acc: 0.8922 - val_loss: 0.2791 - val_acc: 0.9086\n",
      "Epoch 3/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.2730 - acc: 0.9051 - val_loss: 0.2546 - val_acc: 0.9141\n",
      "Epoch 4/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.2532 - acc: 0.9122 - val_loss: 0.2385 - val_acc: 0.9193\n",
      "Epoch 5/6\n",
      "502/502 [==============================] - 5s 9ms/step - loss: 0.2336 - acc: 0.9193 - val_loss: 0.2369 - val_acc: 0.9175\n",
      "Epoch 6/6\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.2165 - acc: 0.9245 - val_loss: 0.2249 - val_acc: 0.9223\n",
      "314/314 [==============================] - 1s 3ms/step\n",
      "Epoch 1/6\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.4951 - acc: 0.8367 - val_loss: 0.2685 - val_acc: 0.9050\n",
      "Epoch 2/6\n",
      "753/753 [==============================] - 9s 13ms/step - loss: 0.2699 - acc: 0.9052 - val_loss: 0.2358 - val_acc: 0.9168\n",
      "Epoch 3/6\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.2361 - acc: 0.9153 - val_loss: 0.2194 - val_acc: 0.9186\n",
      "Epoch 4/6\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.2134 - acc: 0.9235 - val_loss: 0.2055 - val_acc: 0.9289\n",
      "Epoch 5/6\n",
      "753/753 [==============================] - 9s 13ms/step - loss: 0.2013 - acc: 0.9275 - val_loss: 0.2028 - val_acc: 0.9284\n",
      "Epoch 6/6\n",
      "753/753 [==============================] - 9s 13ms/step - loss: 0.1909 - acc: 0.9315 - val_loss: 0.1978 - val_acc: 0.9311\n"
     ]
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = KerasClassifier(model=create_lstm_model, units=256, batch_size=64, dropout=0.2, validation_split=0.2,optimizer__learning_rate=0.1, vocab_length=vocab_length, embedding_matrix=embedding_matrix, max_len=avg_len)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = dict(optimizer__learning_rate=[0.01, 0.1, 0.5],\n",
    "                dropout=[0.2, 0.5], epochs=[20],\n",
    "                units=[32, 64], batch_size=[32, 64])\n",
    "\n",
    "# Perform grid search\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,refit=True,cv=3)\n",
    "grid_result = grid.fit(X_train, y_train, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.928811 using {'units': 64, 'optimizer__learning_rate': 0.1, 'epochs': 6, 'dropout': 0.5, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "#from joblib import dump, load\n",
    "\n",
    "# save model\n",
    "estimator = grid_result.best_estimator_\n",
    "#dump(estimator, \"model_093.joblib\")\n",
    "# Somewhere else\n",
    "#estimator = load(\"your-model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_model_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Plotting\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mplot(lstm_model_history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(lstm_model_history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel Accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_model_history' is not defined"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Access grid search results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "# Extract parameter values for plotting\n",
    "learning_rates = [param['optimizer__learning_rate'] for param in params]\n",
    "dropouts = [param['dropout'] for param in params]\n",
    "units = [param['units'] for param in params]\n",
    "batch_sizes = [param['batch_size'] for param in params]\n",
    "\n",
    "# Plotting the mean test scores for different parameter combinations\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for learning rate vs mean test score\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(learning_rates, means)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Learning Rate vs Mean Test Score')\n",
    "\n",
    "# Plot for dropout vs mean test score\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(dropouts, means)\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Dropout vs Mean Test Score')\n",
    "\n",
    "# Plot for units vs mean test score\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(units, means)\n",
    "plt.xlabel('Units')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Units vs Mean Test Score')\n",
    "\n",
    "# Plot for batch size vs mean test score\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(batch_sizes, means)\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Batch Size vs Mean Test Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best parameters:\", grid_result.best_params_)\n",
    "print(\"Best mean test score:\", grid_result.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:55:20) \n[Clang 16.0.6 ]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
