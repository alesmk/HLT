{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6406adc-7273-4fbb-9dae-b6ee9e4fc153",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a6b2a0",
   "metadata": {},
   "source": [
    "- bert-base-uncased (model_1)\n",
    "- bert-large-whole-word-masking (model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0925a",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56c11e6d-ea4b-4f37-bb7d-d9bc77b7a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "#from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7704334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 150\n",
    "\n",
    "# Dizionario per bert-base-uncased\n",
    "model_1_info = {\n",
    "    \"NAME\": \"bert-base-uncased\",\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 3,\n",
    "    \"LR\": 2e-5\n",
    "}\n",
    "\n",
    "# Dizionario per bert-large-whole-word-masking\n",
    "model_2_info = {\n",
    "    \"NAME\": \"bert-large-whole-word-masking\",\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 4,\n",
    "    \"LR\": 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5577ecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "529af9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install iProgress\n",
    "#pip install ipywidgets\n",
    "#!pip install ipywidgets --upgrade\n",
    "#!pip install ipywidgets tqdm --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65c6ac",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b6f2f1-3ee0-4e3c-ab04-4ff181694ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/train_tweets_Transformers.csv')\n",
    "eval_df = pd.read_csv('../../data/eval_tweets_Transformers.csv')\n",
    "test_df = pd.read_csv('../../data/test_tweets_Transformers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e0ad8-0e47-4732-9677-ab5317586490",
   "metadata": {},
   "source": [
    "### Labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf879a08-3774-4c1f-8d44-5931d715e9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "possible_labels = train_df.cyberbullying_type.unique()\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_dict = le.fit_transform(possible_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725ddd8-9b25-4b09-808a-6c03872bb315",
   "metadata": {},
   "source": [
    "Sostituiamo nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95cecf9f-88dc-4547-8261-5c42cc9ea66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['label'] = le.fit_transform(train_df['cyberbullying_type'])\n",
    "eval_df['label'] = le.fit_transform(eval_df['cyberbullying_type'])\n",
    "test_df['label'] = le.fit_transform(test_df['cyberbullying_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f86a94e0-5b3b-4060-887e-c27898f5a1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_data(df, tokenizer):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df.tweet_text.values, \n",
    "        add_special_tokens = True,         # Add [CLS] and [SEP] special tokens\n",
    "        return_attention_mask = True,      # it will return the attention mask according to the specific tokenizer defined by the max_length attribute\n",
    "        max_length = MAX_LEN,\n",
    "        padding = 'max_length', \n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'              # return pytorch, i tensori servono a rappresentare e manipolare dati multidimensionali in modo efficiente\n",
    "    )\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e44888af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(tokenizer, batch_size):\n",
    "    # Codifica i dati\n",
    "    encoded_data_train = encode_data(train_df, tokenizer)\n",
    "    encoded_data_val = encode_data(eval_df, tokenizer)\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(train_df.label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(eval_df.label.values) #convertire le etichette in tensori\n",
    "\n",
    "    # TensorDataset consente di creare un dataset basato su tensori, \n",
    "    # utile soprattutto quando si lavora con dati che possono essere rappresentati come tensori\n",
    "\n",
    "    #Combines the input IDs, attention masks, and labels for the training set into a TensorDataset.\n",
    "    # This allows the data to be easily accessed and used by PyTorch's DataLoader.\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "    dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "    return dataloader_train, dataloader_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ba33c-0710-42b1-9612-8d62f268614f",
   "metadata": {},
   "source": [
    "We will use f1 score and accuracy per class as performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1aa890-f7b0-47a4-987d-d343c087e5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "def calculate_accuracy(predictions, true_vals):\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "    return accuracy_score(labels_flat, preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "592fc221-4039-440f-a8bf-8749c8068847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val, model):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d0494fe-1780-4438-a34b-3cf334fb0c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_train, dataloader_validation, \n",
    "                epochs, optimizer, scheduler):\n",
    "    \n",
    "    # Initialize history dictionary\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids':    batch[0],\n",
    "                    'attention_mask': batch[1],\n",
    "                    'labels':         batch[2].long(),\n",
    "                    }       \n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "            \n",
    "            _, preds = torch.max(outputs[1], dim=1)\n",
    "            correct_train += torch.sum(preds == inputs['labels'])\n",
    "            total_train += len(inputs['labels'])\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "        \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        train_acc = correct_train.double() / total_train\n",
    "        tqdm.write(f'Average Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        val_accuracy = calculate_accuracy(predictions, true_vals)\n",
    "            \n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        tqdm.write(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "        # Append metrics to history\n",
    "        history['train_loss'].append(loss_train_avg)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_accuracy)\n",
    "\n",
    "    model_name = model.config.name_or_path\n",
    "    torch.save(model.state_dict(), f'../../data/Transformers/finetuned_{model_name}.model')\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d9bca08-996b-4367-a422-98a3a79f66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(model_info):\n",
    "    name = model_info[\"NAME\"]\n",
    "    batch_size = model_info[\"BATCH_SIZE\"]\n",
    "    epochs = model_info[\"EPOCHS\"]\n",
    "    lr = model_info[\"LR\"]\n",
    "\n",
    "    # Inizializzazione del tokenizer BERT basato su WordPiece, \n",
    "    # instanziando una configurazione bert-base (12 layer) e uncased, dato che durante il preprocessing abbiamo eliminato le lettere maiuscole\n",
    "    tokenizer = BertTokenizer.from_pretrained(name, do_lower_case=True)\n",
    "\n",
    "    dataloader_train, dataloader_validation = get_dataloaders(tokenizer, batch_size)\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(name,\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "    # gli ultimi due non sono necessari + settando a False riduciamo il peso computazionale\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr) #, eps=1e-8\n",
    "                  \n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"\\n*** Avvio TRAINING ***\")\n",
    "\n",
    "    train_model(model, dataloader_train, dataloader_validation, epochs, optimizer, scheduler) #\n",
    "    print(\"\\n*** Fine TRAINING ***\")\n",
    "    print(\"\\n -------- \\n\")\n",
    "\n",
    "    _, predictions, true_vals = evaluate(dataloader_validation, model)\n",
    "    accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(confusion_matrix(labels_flat, preds_flat))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(classification_report(labels_flat, preds_flat))\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "852a83fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Avvio TRAINING ***\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017f3cbdb17d43d7b40dbeb4f4723c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2046d48ab854e1aa7c8cde61535dc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_1, tokenizer_1 \u001b[38;5;241m=\u001b[39m execute(model_1_info)\n",
      "Cell \u001b[1;32mIn[27], line 30\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(model_info)\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m*** Avvio TRAINING ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m train_model(model, dataloader_train, dataloader_validation, epochs, optimizer, scheduler) \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m*** Fine TRAINING ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m -------- \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader_train, dataloader_validation, epochs, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     35\u001b[0m loss_train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_1, tokenizer_1 = execute(model_1_info)\n",
    "#model_2, tokenizer_2 = execute(model_2_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aeda6e",
   "metadata": {},
   "source": [
    "## Evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, dataloader_test):\n",
    "    model.eval()\n",
    "    predictions, true_labels = []\n",
    "\n",
    "    for batch in dataloader_test:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        logits = torch.argmax(logits, dim=1).flatten().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        \n",
    "        predictions.extend(logits)\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1-Score: {f1}')\n",
    "\n",
    "# Codifica i dati di test e crea un dataloader\n",
    "tokenizer = BertTokenizer.from_pretrained(model_1_info[\"NAME\"])\n",
    "encoded_data_test = encode_data(test_df, tokenizer)\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(test_df.label.values)\n",
    "\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "dataloader_test = DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=model_1_info[\"BATCH_SIZE\"])\n",
    "\n",
    "# Esegui la valutazione del modello\n",
    "#model = BertForSequenceClassification.from_pretrained(model_1_info[\"NAME\"], num_labels=len(label_dict))\n",
    "#model.to(device)\n",
    "evaluate_model(model_1, dataloader_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc8d8a",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c949224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Style\n",
    "\n",
    "def predict(text, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_dict['input_ids'].to(device)\n",
    "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    prediction_type = next((chiave for chiave, valore in label_dict.items() \n",
    "                           if valore == prediction), None)\n",
    "    return prediction_type\n",
    "    #return invert_label(prediction)  \n",
    "\n",
    "#TODO: aggiungere normalizzazione al tweet in ingresso   \n",
    "def print_category(sentence):\n",
    "    predicted_category = predict(sentence, model_1, tokenizer_1, device)\n",
    "    print(f\"Text: {sentence} \\nPredicted Cyberbullying Category: \", end=\"\")\n",
    "    print(Fore.BLUE + Style.BRIGHT + f\"{predicted_category}\"+ Style.RESET_ALL)\n",
    "    print(\"----------------\")\n",
    "    return\n",
    "    \n",
    "print_category(\"Example of a new tweet that could be cyberbullying.\")\n",
    "print_category(\"fuck you black\")\n",
    "print_category(\"i will rape you\")\n",
    "print_category(\"muslim idiot\")\n",
    "print_category(\"muslim idiot\")\n",
    "print_category(\"hello how are you\")\n",
    "print_category(\"Can anyone else said to this nigger that the dress is blue?\")\n",
    "print_category(\"I'm really happy for your birthday\")\n",
    "print_category(\"In my opinion Allah is not a real god\")\n",
    "print_category(\"I fucking hate Allah\")\n",
    "print_category(\"I appreciate Allah\")\n",
    "print_category(\"Men are better than women\")\n",
    "print_category(\"Bro, you are a Nigga!!!\")\n",
    "print_category(\"You are a shit!!!\")\n",
    "print_category(\"dickhead!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
