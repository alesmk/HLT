{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Duplicates analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I duplicati sono 36\n"
     ]
    }
   ],
   "source": [
    "print(f\"I duplicati sono {df.duplicated().sum()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Our pancakes are selling like hotcakes Shaz - ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>This is the opportunity to prove ourselves lik...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Our pancakes are selling like hotcakes Shaz - ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>@TVWEEKmag: There is only 1 way to stay in the...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>It wouldn't be fair. Kat knows NOTHING of fair...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>A Pakistani court has sentenced 86 members of ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41403</th>\n",
       "      <td>Still, Davis, who is gay, said he pays a socia...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46915</th>\n",
       "      <td>Racism won't stop as long as u stil select ur ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46962</th>\n",
       "      <td>Still, Davis, who is gay, said he pays a socia...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47397</th>\n",
       "      <td>Racism won't stop as long as u stil select ur ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "829    Our pancakes are selling like hotcakes Shaz - ...  not_cyberbullying\n",
       "1712   This is the opportunity to prove ourselves lik...  not_cyberbullying\n",
       "1758   Our pancakes are selling like hotcakes Shaz - ...  not_cyberbullying\n",
       "1984   @TVWEEKmag: There is only 1 way to stay in the...  not_cyberbullying\n",
       "2611   It wouldn't be fair. Kat knows NOTHING of fair...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "20604  A Pakistani court has sentenced 86 members of ...           religion\n",
       "41403  Still, Davis, who is gay, said he pays a socia...          ethnicity\n",
       "46915  Racism won't stop as long as u stil select ur ...          ethnicity\n",
       "46962  Still, Davis, who is gay, said he pays a socia...          ethnicity\n",
       "47397  Racism won't stop as long as u stil select ur ...          ethnicity\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicated with equal tweet_text and equal cyberbullying_type\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we also observe tweets that are identical in tweet text but differ in cyberbullying type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1675"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['tweet_text']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3350"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df[df.duplicated(subset=['tweet_text'], keep = False)]      \n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have found 1639 pairs of duplicates on tweet_text. Let's observe how they are divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d['cyberbullying_type']=='religion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d['cyberbullying_type']=='ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d['cyberbullying_type']=='age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d['cyberbullying_type']=='gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d['cyberbullying_type']=='not_cyberbullying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1580"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[d['cyberbullying_type']=='other_cyberbullying'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we ask ourselves: how many of these pair are composed of 'other_cyberbullying' and 'not_cyberbullying' as types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = d[(d['cyberbullying_type'] == 'other_cyberbullying') | (d['cyberbullying_type'] == 'not_cyberbullying')]\n",
    "dataset.duplicated(subset=['tweet_text']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can be seen, most part of duplicated tweets are populated from the \"other_cyberbullying\" tweets, then we must drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df):\n",
    "    #Drop duplicates and other_cyberbullying tweets\n",
    "    df = df.drop_duplicates()\n",
    "    df = df[df['cyberbullying_type'] != 'other_cyberbullying']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_duplicates(df)\n",
    "df.to_csv(r\"../../data/updated_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(input_file, train_file, eval_file, test_file, train_size=0.8, eval_size=0.1, random_state=None):\n",
    "    # Carica il dataset\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Primo split per ottenere il training set e il test set\n",
    "    train_df, test_df = train_test_split(df, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    # Secondo split per ottenere il validation set dal training set\n",
    "    eval_df_size = eval_size / train_size  # Proporzione del set di valutazione rispetto al training set\n",
    "    train_df, eval_df = train_test_split(train_df, train_size=1 - eval_df_size, random_state=random_state)\n",
    "    \n",
    "    # Salva i dataframe nei rispettivi file\n",
    "    train_df.to_csv(train_file, index=False)\n",
    "    eval_df.to_csv(eval_file, index=False)\n",
    "    test_df.to_csv(test_file, index=False)\n",
    "    \n",
    "    print(f\"Training set salvato in: {train_file}\")\n",
    "    print(f\"Evaluation set salvato in: {eval_file}\")\n",
    "    print(f\"Test set salvato in: {test_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set salvato in: ../../data/train_tweets.csv\n",
      "Evaluation set salvato in: ../../data/eval_tweets.csv\n",
      "Test set salvato in: ../../data/test_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utilizzo della funzione\n",
    "split_dataset('../../data/updated_tweets.csv', '../../data/train_tweets.csv', '../../data/eval_tweets.csv', '../../data/test_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
