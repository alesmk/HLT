{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a51f70-1ab3-4781-adb5-c8f74d044c78",
   "metadata": {},
   "source": [
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab9be8-d755-476f-be33-d4801db23364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "import contractions\n",
    "from functools import reduce\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271741f8-7af6-4bfa-8ef6-6037d260ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening .csv file\n",
    "df = pd.read_csv('../../data/updated_tweets.csv')\n",
    "\n",
    "#Define stop words for text cleaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "stop_words.add(\"mkr\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cf31c-06d4-4e42-a3f3-e96231749b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all textual emojis in the string with null character\n",
    "def remove_textual_emojis(tweet):\n",
    "    tweet = re.sub(r\"(:[DPp3Oo\\(\\)])|(:'[\\)\\(])|(;[\\)\\(])|(-.-)|(^[._]^)|(x[\\(\\)])\", '', tweet)\n",
    "    return tweet #emoji.replace_emoji(tweet,'')\n",
    "\n",
    "\n",
    "#Replace links and mentions (@) with null character\n",
    "def remove_links_mentions(tweet):\n",
    "    return re.sub(r\"((?:\\@|https?\\:\\/\\/|www)\\S+)|(^RT)\", '', tweet)\n",
    "\n",
    "\n",
    "#Remove all hashtags at the end of the sentence and remove the # symbol from all others\n",
    "def remove_hashtag(tweet):\n",
    "    tweet = re.sub(r\"(\\s+#[\\w-]+)+\\s*$\", '', tweet)\n",
    "    return re.sub(r\"#([\\w-]+)\", r'\\1', tweet)\n",
    "\n",
    "\n",
    "#Remove multiple spaces (2+) and remove spaces at the beginning and end of the sentence \n",
    "def remove_spaces(tweet):\n",
    "    tweet = re.sub(r\"\\s{2,}\", ' ', tweet)\n",
    "    tweet = re.sub(r\"^\\s\", '', tweet)\n",
    "    return re.sub(r\"\\s$\", '', tweet)\n",
    "\n",
    "\n",
    "#Remove not ASCII characters (it includes not-textual emojis)\n",
    "def remove_not_ASCII(tweet):\n",
    "    return tweet.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "\n",
    "\n",
    "#Expand contractions (e.g.: can't => cannot)\n",
    "def remove_contractions(tweet):\n",
    "    return contractions.fix(tweet,slang=True)\n",
    "\n",
    "\n",
    "#Remove all stopwords\n",
    "def remove_stopwords(tweet):\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    \n",
    "    # checks whether they are present in stop_words or not\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "            \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "\n",
    "#Remove punctuation symbols\n",
    "def remove_punctuation(tweet):\n",
    "    return remove_spaces(tweet.translate(str.maketrans(\"\", \"\", string.punctuation)))\n",
    "\n",
    "\n",
    "#Lemmatization\n",
    "#Controllare\n",
    "def lemmatization(tweet):\n",
    "    return lemmatizer.lemmatize(tweet)\n",
    "\n",
    "\n",
    "#Stemming\n",
    "#Ok\n",
    "def stemming(tweet):\n",
    "    tmp_tweet = word_tokenize(tweet)\n",
    "    return reduce(lambda x, y: x + ps.stem(y), tmp_tweet, \"\")\n",
    "\n",
    "\n",
    "#Remove multiple doubles in each word of the tweet (e.g.: coooll => cooll)\n",
    "def remove_elongated_words(tweet):\n",
    "    return re.sub(r'(.)\\1+', r'\\1\\1', tweet)\n",
    "\n",
    "\n",
    "#Remove & and $ symbols\n",
    "def remove_special_characters(tweet):\n",
    "    return re.sub(r'[&$]', '',tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f31a9-dfd4-454b-9c17-9d478cfff076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tweet(tweet):\n",
    "    tweet = remove_links_mentions(tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = remove_hashtag(tweet)\n",
    "    tweet = remove_special_characters(tweet)\n",
    " \n",
    "    tweet = remove_spaces(tweet)\n",
    "    tweet = remove_textual_emojis(tweet)\n",
    "    tweet = remove_not_ASCII(tweet)\n",
    "    tweet = remove_contractions(tweet)\n",
    "    tweet = remove_stopwords(tweet)\n",
    "    tweet = remove_punctuation(tweet)\n",
    "    tweet = remove_elongated_words(tweet)\n",
    "    \n",
    "    tweet = lemmatization(tweet)\n",
    "    #tweet = stemming(tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5c6c7-6b78-47df-9796-dccf221c953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply normalization to all tweets\n",
    "df.tweet_text = [normalize_tweet(tweet) for tweet in df.tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9970e-61c6-4994-a8d5-bf10e9cff68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete empty tweets after the normalization\n",
    "df=df.drop(df[(df.tweet_text == r'')].index)  # Rimosse 273 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ef948-7837-4a98-8e60-f292ed832068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Export normalizated tweets\n",
    "df.to_csv(r\"../../data/normalized_tweets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
